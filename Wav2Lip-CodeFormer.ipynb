{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 浪子之心科技\n",
        "# 此代码仅为演示wav2lip推理结束后用CodeFormer进行高清化的过程。\n",
        "# 效果比Wav2Lip-GFPGAN好。\n"
      ],
      "metadata": {
        "id": "ncjUdsIYOoXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qgo-oaI3JU2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2978a876-8f5d-4a1e-e537-f82f23995cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 378, done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 0 (delta 0), pack-reused 378 (from 1)\u001b[K\n",
            "Receiving objects: 100% (378/378), 526.98 KiB | 6.51 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "--2024-10-29 03:10:27--  https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA\n",
            "Resolving iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)... 52.105.227.53, 2a01:111:f402:f0c9::53\n",
            "Connecting to iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)|52.105.227.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 435801865 (416M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’\n",
            "\n",
            "/content/Wav2Lip/ch 100%[===================>] 415.61M  34.7MB/s    in 13s     \n",
            "\n",
            "2024-10-29 03:10:40 (32.5 MB/s) - ‘/content/Wav2Lip/checkpoints/wav2lip_gan.pth’ saved [435801865/435801865]\n",
            "\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.66.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.60.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 6)) (10.4.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 8)) (0.43.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa->-r requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 1)) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 1)) (2024.8.30)\n",
            "--2024-10-29 03:10:47--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "/content/Wav2Lip/fa 100%[===================>]  85.68M  20.6MB/s    in 5.3s    \n",
            "\n",
            "2024-10-29 03:10:53 (16.2 MB/s) - ‘/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting librosa==0.9.1\n",
            "  Using cached librosa-0.9.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.1)\n",
            "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.1) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.1) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.1) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.1) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.1) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.1) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.1) (2024.8.30)\n",
            "Using cached librosa-0.9.1-py3-none-any.whl (213 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.2.post1\n",
            "    Uninstalling librosa-0.10.2.post1:\n",
            "      Successfully uninstalled librosa-0.10.2.post1\n",
            "Successfully installed librosa-0.9.1 resampy-0.4.3\n",
            "\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "#@title 一、下载wav2lip源码和权重并安装wav2lip环境\n",
        "#@title\n",
        "!rm -rf /content/sample_data\n",
        "!mkdir /content/sample_data\n",
        "\n",
        "!git clone https://github.com/zabique/Wav2Lip\n",
        "\n",
        "#download the pretrained model\n",
        "!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'\n",
        "a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "\n",
        "# !pip uninstall tensorflow tensorflow-gpu\n",
        "!cd Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "#download pretrained model for face detection\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "!pip install -q youtube-dl\n",
        "!pip install ffmpeg-python\n",
        "!pip install librosa==0.9.1\n",
        "\n",
        "#this code for recording audio\n",
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "print(\"\\nDone\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 二、下载CodeFormer的源码权重并安装依赖\n",
        "\n",
        "# 下载CodeFormer的源码\n",
        "%cd /content\n",
        "!rm -rf CodeFormer\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "%cd /content/CodeFormer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpa5nWB4wdr7",
        "outputId": "cbdf2220-2ec5-4cdc-b068-6d2e3e8540d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'CodeFormer'...\n",
            "remote: Enumerating objects: 614, done.\u001b[K\n",
            "remote: Counting objects: 100% (298/298), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 614 (delta 204), reused 184 (delta 178), pack-reused 316 (from 1)\u001b[K\n",
            "Receiving objects: 100% (614/614), 17.31 MiB | 17.18 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n",
            "/content/CodeFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载下载CodeFormer的权重\n",
        "%cd /content/CodeFormer\n",
        "!python scripts/download_pretrained_models.py facelib\n",
        "!python scripts/download_pretrained_models.py CodeFormer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ-66EwgweAM",
        "outputId": "05f31b88-ab4f-4491-8485-67e6bd1a129e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeFormer\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CodeFormer/scripts/download_pretrained_models.py\", line 5, in <module>\n",
            "    from basicsr.utils.download_util import load_file_from_url\n",
            "ModuleNotFoundError: No module named 'basicsr'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CodeFormer/scripts/download_pretrained_models.py\", line 5, in <module>\n",
            "    from basicsr.utils.download_util import load_file_from_url\n",
            "ModuleNotFoundError: No module named 'basicsr'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安装CodeFormer的依赖\n",
        "%cd /content/CodeFormer\n",
        "!python basicsr/setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAo8kmNPwd3T",
        "outputId": "b26914b6-ad37-400e-aa02-56c86b433b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating basicsr.egg-info\n",
            "writing basicsr.egg-info/PKG-INFO\n",
            "writing dependency_links to basicsr.egg-info/dependency_links.txt\n",
            "writing requirements to basicsr.egg-info/requires.txt\n",
            "writing top-level names to basicsr.egg-info/top_level.txt\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "reading manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'basicsr.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/basicsr.egg-link (link to .)\n",
            "Adding basicsr 1.3.2 to easy-install.pth file\n",
            "\n",
            "Installed /content/CodeFormer\n",
            "Processing dependencies for basicsr==1.3.2\n",
            "Searching for lpips\n",
            "Reading https://pypi.org/simple/lpips/\n",
            "Downloading https://files.pythonhosted.org/packages/9b/13/1df50c7925d9d2746702719f40e864f51ed66f307b20ad32392f1ad2bb87/lpips-0.1.4-py3-none-any.whl#sha256=fd537af5828b69d2e6ffc0a397bd506dbc28ca183543617690844c08e102ec5e\n",
            "Best match: lpips 0.1.4\n",
            "Processing lpips-0.1.4-py3-none-any.whl\n",
            "Installing lpips-0.1.4-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding lpips 0.1.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/lpips-0.1.4-py3.10.egg\n",
            "Searching for yapf\n",
            "Reading https://pypi.org/simple/yapf/\n",
            "Downloading https://files.pythonhosted.org/packages/32/ec/531851d561ecb656bd58dc102338d0aa07e086788f351c63a9f6b8a00fe6/yapf-0.33.0-py2.py3-none-any.whl#sha256=4c2b59bd5ffe46f3a7da48df87596877189148226ce267c16e8b44240e51578d\n",
            "Best match: yapf 0.33.0\n",
            "Processing yapf-0.33.0-py2.py3-none-any.whl\n",
            "Installing yapf-0.33.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding yapf 0.33.0 to easy-install.pth file\n",
            "Installing yapf script to /usr/local/bin\n",
            "Installing yapf-diff script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/yapf-0.33.0-py3.10.egg\n",
            "Searching for tb-nightly\n",
            "Reading https://pypi.org/simple/tb-nightly/\n",
            "Downloading https://files.pythonhosted.org/packages/a5/32/e2bccb7f84afd8c3b0e7fed7dbb713a0b46ece6c38636ce3396c483abcf5/tb_nightly-2.14.0a20230525-py3-none-any.whl#sha256=57aec995980c39a073c7304b82d83293b85b0e2446905648446ab1052d8ddf26\n",
            "Best match: tb-nightly 2.14.0a20230525\n",
            "Processing tb_nightly-2.14.0a20230525-py3-none-any.whl\n",
            "Installing tb_nightly-2.14.0a20230525-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding tb-nightly 2.14.0a20230525 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/tb_nightly-2.14.0a20230525-py3.10.egg\n",
            "Searching for lmdb\n",
            "Reading https://pypi.org/simple/lmdb/\n",
            "Downloading https://files.pythonhosted.org/packages/83/67/8f32a70336d3ff1149cbd31e5a877997384f78c3940edc0abff95c8a5601/lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=6f8018a947608c4be0dc885c90f477a600be1b71285059a9c68280d36b3fb29b\n",
            "Best match: lmdb 1.4.1\n",
            "Processing lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding lmdb 1.4.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/lmdb-1.4.1-py3.10-linux-x86_64.egg\n",
            "Searching for addict\n",
            "Reading https://pypi.org/simple/addict/\n",
            "Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl#sha256=249bb56bbfd3cdc2a004ea0ff4c2b6ddc84d53bc2194761636eb314d5cfa5dfc\n",
            "Best match: addict 2.4.0\n",
            "Processing addict-2.4.0-py3-none-any.whl\n",
            "Installing addict-2.4.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding addict 2.4.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/addict-2.4.0-py3.10.egg\n",
            "Searching for gdown==4.6.6\n",
            "Best match: gdown 4.6.6\n",
            "Adding gdown 4.6.6 to easy-install.pth file\n",
            "Installing gdown script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tqdm==4.65.0\n",
            "Best match: tqdm 4.65.0\n",
            "Adding tqdm 4.65.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torchvision==0.15.2+cu118\n",
            "Best match: torchvision 0.15.2+cu118\n",
            "Adding torchvision 0.15.2+cu118 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for torch==2.0.1+cu118\n",
            "Best match: torch 2.0.1+cu118\n",
            "Adding torch 2.0.1+cu118 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scipy==1.10.1\n",
            "Best match: scipy 1.10.1\n",
            "Adding scipy 1.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for scikit-image==0.19.3\n",
            "Best match: scikit-image 0.19.3\n",
            "Adding scikit-image 0.19.3 to easy-install.pth file\n",
            "Installing skivi script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests==2.27.1\n",
            "Best match: requests 2.27.1\n",
            "Adding requests 2.27.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Pillow==8.4.0\n",
            "Best match: Pillow 8.4.0\n",
            "Adding Pillow 8.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for opencv-python==4.7.0.72\n",
            "Best match: opencv-python 4.7.0.72\n",
            "Adding opencv-python 4.7.0.72 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for numpy==1.22.4\n",
            "Best match: numpy 1.22.4\n",
            "Adding numpy 1.22.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.10 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for future==0.18.3\n",
            "Best match: future 0.18.3\n",
            "Adding future 0.18.3 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for beautifulsoup4==4.11.2\n",
            "Best match: beautifulsoup4 4.11.2\n",
            "Adding beautifulsoup4 4.11.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for six==1.16.0\n",
            "Best match: six 1.16.0\n",
            "Adding six 1.16.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for filelock==3.12.0\n",
            "Best match: filelock 3.12.0\n",
            "Adding filelock 3.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tomli==2.0.1\n",
            "Best match: tomli 2.0.1\n",
            "Adding tomli 2.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for triton==2.0.0\n",
            "Best match: triton 2.0.0\n",
            "Adding triton 2.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Jinja2==3.1.2\n",
            "Best match: Jinja2 3.1.2\n",
            "Adding Jinja2 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for networkx==3.1\n",
            "Best match: networkx 3.1\n",
            "Adding networkx 3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for sympy==1.11.1\n",
            "Best match: sympy 1.11.1\n",
            "Adding sympy 1.11.1 to easy-install.pth file\n",
            "Installing isympy script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for typing-extensions==4.5.0\n",
            "Best match: typing-extensions 4.5.0\n",
            "Adding typing-extensions 4.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for wheel==0.40.0\n",
            "Best match: wheel 0.40.0\n",
            "Adding wheel 0.40.0 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Werkzeug==2.3.0\n",
            "Best match: Werkzeug 2.3.0\n",
            "Adding Werkzeug 2.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tensorboard-data-server==0.7.0\n",
            "Best match: tensorboard-data-server 0.7.0\n",
            "Adding tensorboard-data-server 0.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for setuptools==67.7.2\n",
            "Best match: setuptools 67.7.2\n",
            "Adding setuptools 67.7.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for protobuf==3.20.3\n",
            "Best match: protobuf 3.20.3\n",
            "Adding protobuf 3.20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for Markdown==3.4.3\n",
            "Best match: Markdown 3.4.3\n",
            "Adding Markdown 3.4.3 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for google-auth-oauthlib==1.0.0\n",
            "Best match: google-auth-oauthlib 1.0.0\n",
            "Adding google-auth-oauthlib 1.0.0 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for google-auth==2.17.3\n",
            "Best match: google-auth 2.17.3\n",
            "Adding google-auth 2.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for grpcio==1.54.0\n",
            "Best match: grpcio 1.54.0\n",
            "Adding grpcio 1.54.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for absl-py==1.4.0\n",
            "Best match: absl-py 1.4.0\n",
            "Adding absl-py 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for packaging==23.1\n",
            "Best match: packaging 23.1\n",
            "Adding packaging 23.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PyWavelets==1.4.1\n",
            "Best match: PyWavelets 1.4.1\n",
            "Adding PyWavelets 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for tifffile==2023.4.12\n",
            "Best match: tifffile 2023.4.12\n",
            "Adding tifffile 2023.4.12 to easy-install.pth file\n",
            "Installing lsm2bin script to /usr/local/bin\n",
            "Installing tiff2fsspec script to /usr/local/bin\n",
            "Installing tiffcomment script to /usr/local/bin\n",
            "Installing tifffile script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for imageio==2.25.1\n",
            "Best match: imageio 2.25.1\n",
            "Adding imageio 2.25.1 to easy-install.pth file\n",
            "Installing imageio_download_bin script to /usr/local/bin\n",
            "Installing imageio_remove_bin script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for idna==3.4\n",
            "Best match: idna 3.4\n",
            "Adding idna 3.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for charset-normalizer==2.0.12\n",
            "Best match: charset-normalizer 2.0.12\n",
            "Adding charset-normalizer 2.0.12 to easy-install.pth file\n",
            "Installing normalizer script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for certifi==2022.12.7\n",
            "Best match: certifi 2022.12.7\n",
            "Adding certifi 2022.12.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for urllib3==1.26.15\n",
            "Best match: urllib3 1.26.15\n",
            "Adding urllib3 1.26.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for soupsieve==2.4.1\n",
            "Best match: soupsieve 2.4.1\n",
            "Adding soupsieve 2.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for PySocks==1.7.1\n",
            "Best match: PySocks 1.7.1\n",
            "Adding PySocks 1.7.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for lit==16.0.5\n",
            "Best match: lit 16.0.5\n",
            "Adding lit 16.0.5 to easy-install.pth file\n",
            "Installing lit script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cmake==3.25.2\n",
            "Best match: cmake 3.25.2\n",
            "Adding cmake 3.25.2 to easy-install.pth file\n",
            "Installing cmake script to /usr/local/bin\n",
            "Installing cpack script to /usr/local/bin\n",
            "Installing ctest script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for MarkupSafe==2.1.2\n",
            "Best match: MarkupSafe 2.1.2\n",
            "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for mpmath==1.3.0\n",
            "Best match: mpmath 1.3.0\n",
            "Adding mpmath 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for rsa==4.9\n",
            "Best match: rsa 4.9\n",
            "Adding rsa 4.9 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyasn1-modules==0.3.0\n",
            "Best match: pyasn1-modules 0.3.0\n",
            "Adding pyasn1-modules 0.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for cachetools==5.3.0\n",
            "Best match: cachetools 5.3.0\n",
            "Adding cachetools 5.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for oauthlib==3.2.2\n",
            "Best match: oauthlib 3.2.2\n",
            "Adding oauthlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Searching for pyasn1==0.5.0\n",
            "Best match: pyasn1 0.5.0\n",
            "Adding pyasn1 0.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for basicsr==1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vsphzJawLF-f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "d719c307-0fd2-4c65-a059-0930e2ad7cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘output’: File exists\n",
            "mkdir: cannot create directory ‘input’: File exists\n",
            "/content/input\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-07ea5b92-4ef8-4f40-9cd9-ea7dfe7d9c98\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-07ea5b92-4ef8-4f40-9cd9-ea7dfe7d9c98\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving basic_vedio.mp4 to basic_vedio.mp4\n"
          ]
        }
      ],
      "source": [
        "#@title 三、上传视频和音频\n",
        "# 创建相关的文件夹\n",
        "%cd /content\n",
        "!mkdir output\n",
        "!mkdir input\n",
        "# 上传音视频\n",
        "%cd /content/input\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 四、用wav2lip初步生成修改嘴型后的视频\n",
        "\n",
        "# 先清理之前生成的临时文件\n",
        "%cd /content\n",
        "!rm -rf output\n",
        "!mkdir output\n",
        "!rm -rf /content/Wav2Lip/temp/result.avi\n",
        "!rm -rf /content/Wav2Lip/temp/temp.wav\n",
        "!rm -rf /content/Wav2Lip/results/result_voice.mp4\n",
        "!rm -rf images\n",
        "!mkdir images\n",
        "%cd /content/CodeFormer\n",
        "!rm -rf results\n",
        "!mkdir results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juHcmv6ouFHH",
        "outputId": "c1aad9fb-0ba4-4894-9be8-a7f550e78744"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/CodeFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2a9451-da27-455e-9422-61bc263936b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Wav2Lip\n",
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 281\n",
            "/content/Wav2Lip/audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
            "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "(80, 787)\n",
            "Length of mel chunks: 243\n",
            "  0% 0/2 [00:00<?, ?it/s]/content/Wav2Lip/face_detection/detection/sfd/sfd_detector.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_weights = torch.load(path_to_detector)\n",
            "\n",
            "  0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 1/16 [00:41<10:20, 41.40s/it]\u001b[A\n",
            " 12% 2/16 [00:44<04:24, 18.88s/it]\u001b[A\n",
            " 19% 3/16 [00:47<02:30, 11.60s/it]\u001b[A\n",
            " 25% 4/16 [00:50<01:39,  8.27s/it]\u001b[A\n",
            " 31% 5/16 [00:53<01:09,  6.33s/it]\u001b[A\n",
            " 38% 6/16 [00:56<00:51,  5.16s/it]\u001b[A\n",
            " 44% 7/16 [00:59<00:39,  4.44s/it]\u001b[A\n",
            " 50% 8/16 [01:02<00:32,  4.04s/it]\u001b[A\n",
            " 56% 9/16 [01:05<00:25,  3.68s/it]\u001b[A\n",
            " 62% 10/16 [01:08<00:20,  3.44s/it]\u001b[A\n",
            " 69% 11/16 [01:11<00:16,  3.28s/it]\u001b[A\n",
            " 75% 12/16 [01:14<00:12,  3.22s/it]\u001b[A\n",
            " 81% 13/16 [01:17<00:09,  3.13s/it]\u001b[A\n",
            " 88% 14/16 [01:20<00:06,  3.07s/it]\u001b[A\n",
            " 94% 15/16 [01:23<00:03,  3.03s/it]\u001b[A\n",
            "100% 16/16 [01:31<00:00,  5.72s/it]\n",
            "Load checkpoint from: checkpoints/wav2lip_gan.pth\n",
            "/content/Wav2Lip/inference.py:162: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n",
            "Model loaded\n",
            "100% 2/2 [01:54<00:00, 57.09s/it]\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mInput #0, wav, from '/content/input/A_10s.wav':\n",
            "  Duration: 00:00:09.84, bitrate: 1411 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "Input #1, avi, from 'temp/result.avi':\n",
            "  Metadata:\n",
            "    software        : Lavf59.27.100\n",
            "  Duration: 00:00:09.72, start: 0.000000, bitrate: 2860 kb/s\n",
            "  Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 720x1280 [SAR 1:1 DAR 9:16], 2862 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/result_voice.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 720x1280 [SAR 1:1 DAR 9:16], q=2-31, 25 fps, 12800 tbn\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=  243 fps= 20 q=-1.0 Lsize=    1854kB time=00:00:09.82 bitrate=1546.3kbits/s speed=0.813x    \n",
            "video:1689kB audio:156kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.502812%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mframe I:1     Avg QP:21.48  size: 39750\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mframe P:114   Avg QP:21.31  size: 12701\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mframe B:128   Avg QP:25.13  size:  1885\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mconsecutive B-frames: 11.5% 52.7%  6.2% 29.6%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mmb I  I16..4: 10.0% 88.3%  1.6%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mmb P  I16..4:  0.9%  7.7%  0.1%  P16..4: 38.2% 10.3%  7.4%  0.0%  0.0%    skip:35.3%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mmb B  I16..4:  0.2%  0.7%  0.0%  B16..8: 32.2%  0.7%  0.1%  direct: 0.2%  skip:65.9%  L0:47.9% L1:48.7% BI: 3.4%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0m8x8 transform intra:87.0% inter:83.6%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mcoded y,uvDC,uvAC intra: 68.3% 65.2% 5.5% inter: 11.3% 11.4% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mi16 v,h,dc,p: 44% 13% 31% 12%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 52% 11% 31%  1%  1%  1%  1%  2%  1%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 66% 12% 10%  2%  2%  3%  2%  2%  1%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mi8c dc,h,v,p: 45% 18% 35%  3%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mWeighted P-Frames: Y:1.8% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mref P L0: 71.3% 13.0% 11.6%  4.0%  0.0%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mref B L0: 87.3% 11.4%  1.3%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mref B L1: 99.2%  0.8%\n",
            "\u001b[1;36m[libx264 @ 0x58c41b4425c0] \u001b[0mkb/s:1423.06\n",
            "\u001b[1;36m[aac @ 0x58c41b44be80] \u001b[0mQavg: 206.491\n"
          ]
        }
      ],
      "source": [
        "# 用wav2lip进行推理\n",
        "# checkpoints 可以用wav2lip.pth 或者wav2lip_gan.pt\n",
        "%cd /content/Wav2Lip\n",
        "!python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face '/content/input/basic_vedio.mp4' --audio '/content/input/A_10s.wav'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将Wav2Lip生成的视频转化成图片保存到images\n",
        "%cd /content\n",
        "!mkdir images\n",
        "%cd /content/Wav2Lip\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "import os\n",
        "\n",
        "vidcap = cv2.VideoCapture(\"/content/Wav2Lip/results/result_voice.mp4\")\n",
        "numberOfFrames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "print(\"FPS: \", fps, \"Frames: \", numberOfFrames)\n",
        "\n",
        "for frameNumber in tqdm(range(numberOfFrames)):\n",
        "    _,image = vidcap.read()\n",
        "    cv2.imwrite(path.join('/content/images', str(frameNumber).zfill(4)+'.jpg'), image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ap1pwvjyGjj",
        "outputId": "811be743-f5aa-45ba-8f1a-1a7b5ed54b58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "mkdir: cannot create directory ‘images’: File exists\n",
            "/content/Wav2Lip\n",
            "FPS:  25.0 Frames:  243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 243/243 [00:01<00:00, 146.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 五、用CodeFormer进行人脸修复\n",
        "\n",
        "%cd /content/CodeFormer\n",
        "# 定义相关函数\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img"
      ],
      "metadata": {
        "id": "Km1SuJc0xRJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9d0bc6-be73-49a9-867f-b78c067f0c3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lpips"
      ],
      "metadata": {
        "id": "cH-cQEQYSpg_",
        "outputId": "3763fb85-bc8c-496a-f557-77dae71dc5fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr"
      ],
      "metadata": {
        "id": "tVjqcoKXTWwW",
        "outputId": "8a2810c5-f46a-44a1-90be-c68bfc6535fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting basicsr\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from basicsr)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.0.0)\n",
            "Collecting lmdb (from basicsr)\n",
            "  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from basicsr) (10.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr) (1.13.1)\n",
            "Collecting tb-nightly (from basicsr)\n",
            "  Downloading tb_nightly-2.19.0a20241024-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from basicsr) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from basicsr) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from basicsr) (4.66.5)\n",
            "Collecting yapf (from basicsr)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->basicsr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7->basicsr) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (8.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (4.3.6)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr) (2.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tb_nightly-2.19.0a20241024-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: basicsr\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214817 sha256=e457abb2d243bc9f84540fcf5f157c152e81f1c55b2e2ffabe641eb03c42f30b\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/83/99/2d8437cc652a01af27df5ff037a4075e95b52d67705c5f30ca\n",
            "Successfully built basicsr\n",
            "Installing collected packages: lmdb, addict, yapf, tb-nightly, basicsr\n",
            "Successfully installed addict-2.4.0 basicsr-1.4.2 lmdb-1.5.1 tb-nightly-2.19.0a20241024 yapf-0.40.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 用CodeFormer进行推理\n",
        "%cd /content/CodeFormer\n",
        "## 只修复人脸\n",
        "# CODEFORMER_FIDELITY = 0.5\n",
        "# !python inference_codeformer.py -w $CODEFORMER_FIDELITY --has_aligned --input_path /content/images\n",
        "\n",
        "# whole images ##整体图片修复\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path /content/images --bg_upsampler realesrgan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t87g87LoxRSq",
        "outputId": "b3bc9b8e-3e13-4e30-86ff-ba633cfe764b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeFormer\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/RealESRGAN_x2plus.pth\" to /content/CodeFormer/weights/realesrgan/RealESRGAN_x2plus.pth\n",
            "\n",
            "100% 64.0M/64.0M [00:00<00:00, 342MB/s]\n",
            "/content/CodeFormer/basicsr/utils/realesrgan_utils.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth\" to /content/CodeFormer/weights/CodeFormer/codeformer.pth\n",
            "\n",
            "100% 359M/359M [00:01<00:00, 349MB/s]\n",
            "/content/CodeFormer/inference_codeformer.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path)['params_ema']\n",
            "Face detection model: retinaface_resnet50\n",
            "Background upsampling: True, Face upsampling: False\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/CodeFormer/weights/facelib/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 223MB/s] \n",
            "/content/CodeFormer/facelib/detection/__init__.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  load_net = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
            "Downloading: \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/parsing_parsenet.pth\" to /content/CodeFormer/weights/facelib/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 193MB/s]\n",
            "/content/CodeFormer/facelib/parsing/__init__.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  load_net = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
            "[1/243] Processing: 0000.jpg\n",
            "\tdetect 1 faces\n",
            "[2/243] Processing: 0001.jpg\n",
            "\tdetect 1 faces\n",
            "[3/243] Processing: 0002.jpg\n",
            "\tdetect 1 faces\n",
            "[4/243] Processing: 0003.jpg\n",
            "\tdetect 1 faces\n",
            "[5/243] Processing: 0004.jpg\n",
            "\tdetect 1 faces\n",
            "[6/243] Processing: 0005.jpg\n",
            "\tdetect 1 faces\n",
            "[7/243] Processing: 0006.jpg\n",
            "\tdetect 1 faces\n",
            "[8/243] Processing: 0007.jpg\n",
            "\tdetect 1 faces\n",
            "[9/243] Processing: 0008.jpg\n",
            "\tdetect 1 faces\n",
            "[10/243] Processing: 0009.jpg\n",
            "\tdetect 1 faces\n",
            "[11/243] Processing: 0010.jpg\n",
            "\tdetect 1 faces\n",
            "[12/243] Processing: 0011.jpg\n",
            "\tdetect 1 faces\n",
            "[13/243] Processing: 0012.jpg\n",
            "\tdetect 1 faces\n",
            "[14/243] Processing: 0013.jpg\n",
            "\tdetect 1 faces\n",
            "[15/243] Processing: 0014.jpg\n",
            "\tdetect 1 faces\n",
            "[16/243] Processing: 0015.jpg\n",
            "\tdetect 1 faces\n",
            "[17/243] Processing: 0016.jpg\n",
            "\tdetect 1 faces\n",
            "[18/243] Processing: 0017.jpg\n",
            "\tdetect 1 faces\n",
            "[19/243] Processing: 0018.jpg\n",
            "\tdetect 1 faces\n",
            "[20/243] Processing: 0019.jpg\n",
            "\tdetect 1 faces\n",
            "[21/243] Processing: 0020.jpg\n",
            "\tdetect 1 faces\n",
            "[22/243] Processing: 0021.jpg\n",
            "\tdetect 1 faces\n",
            "[23/243] Processing: 0022.jpg\n",
            "\tdetect 1 faces\n",
            "[24/243] Processing: 0023.jpg\n",
            "\tdetect 1 faces\n",
            "[25/243] Processing: 0024.jpg\n",
            "\tdetect 1 faces\n",
            "[26/243] Processing: 0025.jpg\n",
            "\tdetect 1 faces\n",
            "[27/243] Processing: 0026.jpg\n",
            "\tdetect 1 faces\n",
            "[28/243] Processing: 0027.jpg\n",
            "\tdetect 1 faces\n",
            "[29/243] Processing: 0028.jpg\n",
            "\tdetect 1 faces\n",
            "[30/243] Processing: 0029.jpg\n",
            "\tdetect 1 faces\n",
            "[31/243] Processing: 0030.jpg\n",
            "\tdetect 1 faces\n",
            "[32/243] Processing: 0031.jpg\n",
            "\tdetect 1 faces\n",
            "[33/243] Processing: 0032.jpg\n",
            "\tdetect 1 faces\n",
            "[34/243] Processing: 0033.jpg\n",
            "\tdetect 1 faces\n",
            "[35/243] Processing: 0034.jpg\n",
            "\tdetect 1 faces\n",
            "[36/243] Processing: 0035.jpg\n",
            "\tdetect 1 faces\n",
            "[37/243] Processing: 0036.jpg\n",
            "\tdetect 1 faces\n",
            "[38/243] Processing: 0037.jpg\n",
            "\tdetect 1 faces\n",
            "[39/243] Processing: 0038.jpg\n",
            "\tdetect 1 faces\n",
            "[40/243] Processing: 0039.jpg\n",
            "\tdetect 1 faces\n",
            "[41/243] Processing: 0040.jpg\n",
            "\tdetect 1 faces\n",
            "[42/243] Processing: 0041.jpg\n",
            "\tdetect 1 faces\n",
            "[43/243] Processing: 0042.jpg\n",
            "\tdetect 1 faces\n",
            "[44/243] Processing: 0043.jpg\n",
            "\tdetect 1 faces\n",
            "[45/243] Processing: 0044.jpg\n",
            "\tdetect 1 faces\n",
            "[46/243] Processing: 0045.jpg\n",
            "\tdetect 1 faces\n",
            "[47/243] Processing: 0046.jpg\n",
            "\tdetect 1 faces\n",
            "[48/243] Processing: 0047.jpg\n",
            "\tdetect 1 faces\n",
            "[49/243] Processing: 0048.jpg\n",
            "\tdetect 1 faces\n",
            "[50/243] Processing: 0049.jpg\n",
            "\tdetect 1 faces\n",
            "[51/243] Processing: 0050.jpg\n",
            "\tdetect 1 faces\n",
            "[52/243] Processing: 0051.jpg\n",
            "\tdetect 1 faces\n",
            "[53/243] Processing: 0052.jpg\n",
            "\tdetect 1 faces\n",
            "[54/243] Processing: 0053.jpg\n",
            "\tdetect 1 faces\n",
            "[55/243] Processing: 0054.jpg\n",
            "\tdetect 1 faces\n",
            "[56/243] Processing: 0055.jpg\n",
            "\tdetect 1 faces\n",
            "[57/243] Processing: 0056.jpg\n",
            "\tdetect 1 faces\n",
            "[58/243] Processing: 0057.jpg\n",
            "\tdetect 1 faces\n",
            "[59/243] Processing: 0058.jpg\n",
            "\tdetect 1 faces\n",
            "[60/243] Processing: 0059.jpg\n",
            "\tdetect 1 faces\n",
            "[61/243] Processing: 0060.jpg\n",
            "\tdetect 1 faces\n",
            "[62/243] Processing: 0061.jpg\n",
            "\tdetect 1 faces\n",
            "[63/243] Processing: 0062.jpg\n",
            "\tdetect 1 faces\n",
            "[64/243] Processing: 0063.jpg\n",
            "\tdetect 1 faces\n",
            "[65/243] Processing: 0064.jpg\n",
            "\tdetect 1 faces\n",
            "[66/243] Processing: 0065.jpg\n",
            "\tdetect 1 faces\n",
            "[67/243] Processing: 0066.jpg\n",
            "\tdetect 1 faces\n",
            "[68/243] Processing: 0067.jpg\n",
            "\tdetect 1 faces\n",
            "[69/243] Processing: 0068.jpg\n",
            "\tdetect 1 faces\n",
            "[70/243] Processing: 0069.jpg\n",
            "\tdetect 1 faces\n",
            "[71/243] Processing: 0070.jpg\n",
            "\tdetect 1 faces\n",
            "[72/243] Processing: 0071.jpg\n",
            "\tdetect 1 faces\n",
            "[73/243] Processing: 0072.jpg\n",
            "\tdetect 1 faces\n",
            "[74/243] Processing: 0073.jpg\n",
            "\tdetect 1 faces\n",
            "[75/243] Processing: 0074.jpg\n",
            "\tdetect 1 faces\n",
            "[76/243] Processing: 0075.jpg\n",
            "\tdetect 1 faces\n",
            "[77/243] Processing: 0076.jpg\n",
            "\tdetect 1 faces\n",
            "[78/243] Processing: 0077.jpg\n",
            "\tdetect 1 faces\n",
            "[79/243] Processing: 0078.jpg\n",
            "\tdetect 1 faces\n",
            "[80/243] Processing: 0079.jpg\n",
            "\tdetect 1 faces\n",
            "[81/243] Processing: 0080.jpg\n",
            "\tdetect 1 faces\n",
            "[82/243] Processing: 0081.jpg\n",
            "\tdetect 1 faces\n",
            "[83/243] Processing: 0082.jpg\n",
            "\tdetect 1 faces\n",
            "[84/243] Processing: 0083.jpg\n",
            "\tdetect 1 faces\n",
            "[85/243] Processing: 0084.jpg\n",
            "\tdetect 1 faces\n",
            "[86/243] Processing: 0085.jpg\n",
            "\tdetect 1 faces\n",
            "[87/243] Processing: 0086.jpg\n",
            "\tdetect 1 faces\n",
            "[88/243] Processing: 0087.jpg\n",
            "\tdetect 1 faces\n",
            "[89/243] Processing: 0088.jpg\n",
            "\tdetect 1 faces\n",
            "[90/243] Processing: 0089.jpg\n",
            "\tdetect 1 faces\n",
            "[91/243] Processing: 0090.jpg\n",
            "\tdetect 1 faces\n",
            "[92/243] Processing: 0091.jpg\n",
            "\tdetect 1 faces\n",
            "[93/243] Processing: 0092.jpg\n",
            "\tdetect 1 faces\n",
            "[94/243] Processing: 0093.jpg\n",
            "\tdetect 1 faces\n",
            "[95/243] Processing: 0094.jpg\n",
            "\tdetect 1 faces\n",
            "[96/243] Processing: 0095.jpg\n",
            "\tdetect 1 faces\n",
            "[97/243] Processing: 0096.jpg\n",
            "\tdetect 1 faces\n",
            "[98/243] Processing: 0097.jpg\n",
            "\tdetect 1 faces\n",
            "[99/243] Processing: 0098.jpg\n",
            "\tdetect 1 faces\n",
            "[100/243] Processing: 0099.jpg\n",
            "\tdetect 1 faces\n",
            "[101/243] Processing: 0100.jpg\n",
            "\tdetect 1 faces\n",
            "[102/243] Processing: 0101.jpg\n",
            "\tdetect 1 faces\n",
            "[103/243] Processing: 0102.jpg\n",
            "\tdetect 1 faces\n",
            "[104/243] Processing: 0103.jpg\n",
            "\tdetect 1 faces\n",
            "[105/243] Processing: 0104.jpg\n",
            "\tdetect 1 faces\n",
            "[106/243] Processing: 0105.jpg\n",
            "\tdetect 1 faces\n",
            "[107/243] Processing: 0106.jpg\n",
            "\tdetect 1 faces\n",
            "[108/243] Processing: 0107.jpg\n",
            "\tdetect 1 faces\n",
            "[109/243] Processing: 0108.jpg\n",
            "\tdetect 1 faces\n",
            "[110/243] Processing: 0109.jpg\n",
            "\tdetect 1 faces\n",
            "[111/243] Processing: 0110.jpg\n",
            "\tdetect 1 faces\n",
            "[112/243] Processing: 0111.jpg\n",
            "\tdetect 1 faces\n",
            "[113/243] Processing: 0112.jpg\n",
            "\tdetect 1 faces\n",
            "[114/243] Processing: 0113.jpg\n",
            "\tdetect 1 faces\n",
            "[115/243] Processing: 0114.jpg\n",
            "\tdetect 1 faces\n",
            "[116/243] Processing: 0115.jpg\n",
            "\tdetect 1 faces\n",
            "[117/243] Processing: 0116.jpg\n",
            "\tdetect 1 faces\n",
            "[118/243] Processing: 0117.jpg\n",
            "\tdetect 1 faces\n",
            "[119/243] Processing: 0118.jpg\n",
            "\tdetect 1 faces\n",
            "[120/243] Processing: 0119.jpg\n",
            "\tdetect 1 faces\n",
            "[121/243] Processing: 0120.jpg\n",
            "\tdetect 1 faces\n",
            "[122/243] Processing: 0121.jpg\n",
            "\tdetect 1 faces\n",
            "[123/243] Processing: 0122.jpg\n",
            "\tdetect 1 faces\n",
            "[124/243] Processing: 0123.jpg\n",
            "\tdetect 1 faces\n",
            "[125/243] Processing: 0124.jpg\n",
            "\tdetect 1 faces\n",
            "[126/243] Processing: 0125.jpg\n",
            "\tdetect 1 faces\n",
            "[127/243] Processing: 0126.jpg\n",
            "\tdetect 1 faces\n",
            "[128/243] Processing: 0127.jpg\n",
            "\tdetect 1 faces\n",
            "[129/243] Processing: 0128.jpg\n",
            "\tdetect 1 faces\n",
            "[130/243] Processing: 0129.jpg\n",
            "\tdetect 1 faces\n",
            "[131/243] Processing: 0130.jpg\n",
            "\tdetect 1 faces\n",
            "[132/243] Processing: 0131.jpg\n",
            "\tdetect 1 faces\n",
            "[133/243] Processing: 0132.jpg\n",
            "\tdetect 1 faces\n",
            "[134/243] Processing: 0133.jpg\n",
            "\tdetect 1 faces\n",
            "[135/243] Processing: 0134.jpg\n",
            "\tdetect 1 faces\n",
            "[136/243] Processing: 0135.jpg\n",
            "\tdetect 1 faces\n",
            "[137/243] Processing: 0136.jpg\n",
            "\tdetect 1 faces\n",
            "[138/243] Processing: 0137.jpg\n",
            "\tdetect 1 faces\n",
            "[139/243] Processing: 0138.jpg\n",
            "\tdetect 1 faces\n",
            "[140/243] Processing: 0139.jpg\n",
            "\tdetect 1 faces\n",
            "[141/243] Processing: 0140.jpg\n",
            "\tdetect 1 faces\n",
            "[142/243] Processing: 0141.jpg\n",
            "\tdetect 1 faces\n",
            "[143/243] Processing: 0142.jpg\n",
            "\tdetect 1 faces\n",
            "[144/243] Processing: 0143.jpg\n",
            "\tdetect 1 faces\n",
            "[145/243] Processing: 0144.jpg\n",
            "\tdetect 1 faces\n",
            "[146/243] Processing: 0145.jpg\n",
            "\tdetect 1 faces\n",
            "[147/243] Processing: 0146.jpg\n",
            "\tdetect 1 faces\n",
            "[148/243] Processing: 0147.jpg\n",
            "\tdetect 1 faces\n",
            "[149/243] Processing: 0148.jpg\n",
            "\tdetect 1 faces\n",
            "[150/243] Processing: 0149.jpg\n",
            "\tdetect 1 faces\n",
            "[151/243] Processing: 0150.jpg\n",
            "\tdetect 1 faces\n",
            "[152/243] Processing: 0151.jpg\n",
            "\tdetect 1 faces\n",
            "[153/243] Processing: 0152.jpg\n",
            "\tdetect 1 faces\n",
            "[154/243] Processing: 0153.jpg\n",
            "\tdetect 1 faces\n",
            "[155/243] Processing: 0154.jpg\n",
            "\tdetect 1 faces\n",
            "[156/243] Processing: 0155.jpg\n",
            "\tdetect 1 faces\n",
            "[157/243] Processing: 0156.jpg\n",
            "\tdetect 1 faces\n",
            "[158/243] Processing: 0157.jpg\n",
            "\tdetect 1 faces\n",
            "[159/243] Processing: 0158.jpg\n",
            "\tdetect 1 faces\n",
            "[160/243] Processing: 0159.jpg\n",
            "\tdetect 1 faces\n",
            "[161/243] Processing: 0160.jpg\n",
            "\tdetect 1 faces\n",
            "[162/243] Processing: 0161.jpg\n",
            "\tdetect 1 faces\n",
            "[163/243] Processing: 0162.jpg\n",
            "\tdetect 1 faces\n",
            "[164/243] Processing: 0163.jpg\n",
            "\tdetect 1 faces\n",
            "[165/243] Processing: 0164.jpg\n",
            "\tdetect 1 faces\n",
            "[166/243] Processing: 0165.jpg\n",
            "\tdetect 1 faces\n",
            "[167/243] Processing: 0166.jpg\n",
            "\tdetect 1 faces\n",
            "[168/243] Processing: 0167.jpg\n",
            "\tdetect 1 faces\n",
            "[169/243] Processing: 0168.jpg\n",
            "\tdetect 1 faces\n",
            "[170/243] Processing: 0169.jpg\n",
            "\tdetect 1 faces\n",
            "[171/243] Processing: 0170.jpg\n",
            "\tdetect 1 faces\n",
            "[172/243] Processing: 0171.jpg\n",
            "\tdetect 1 faces\n",
            "[173/243] Processing: 0172.jpg\n",
            "\tdetect 1 faces\n",
            "[174/243] Processing: 0173.jpg\n",
            "\tdetect 1 faces\n",
            "[175/243] Processing: 0174.jpg\n",
            "\tdetect 1 faces\n",
            "[176/243] Processing: 0175.jpg\n",
            "\tdetect 1 faces\n",
            "[177/243] Processing: 0176.jpg\n",
            "\tdetect 1 faces\n",
            "[178/243] Processing: 0177.jpg\n",
            "\tdetect 1 faces\n",
            "[179/243] Processing: 0178.jpg\n",
            "\tdetect 1 faces\n",
            "[180/243] Processing: 0179.jpg\n",
            "\tdetect 1 faces\n",
            "[181/243] Processing: 0180.jpg\n",
            "\tdetect 1 faces\n",
            "[182/243] Processing: 0181.jpg\n",
            "\tdetect 1 faces\n",
            "[183/243] Processing: 0182.jpg\n",
            "\tdetect 1 faces\n",
            "[184/243] Processing: 0183.jpg\n",
            "\tdetect 1 faces\n",
            "[185/243] Processing: 0184.jpg\n",
            "\tdetect 1 faces\n",
            "[186/243] Processing: 0185.jpg\n",
            "\tdetect 1 faces\n",
            "[187/243] Processing: 0186.jpg\n",
            "\tdetect 1 faces\n",
            "[188/243] Processing: 0187.jpg\n",
            "\tdetect 1 faces\n",
            "[189/243] Processing: 0188.jpg\n",
            "\tdetect 1 faces\n",
            "[190/243] Processing: 0189.jpg\n",
            "\tdetect 1 faces\n",
            "[191/243] Processing: 0190.jpg\n",
            "\tdetect 1 faces\n",
            "[192/243] Processing: 0191.jpg\n",
            "\tdetect 1 faces\n",
            "[193/243] Processing: 0192.jpg\n",
            "\tdetect 1 faces\n",
            "[194/243] Processing: 0193.jpg\n",
            "\tdetect 1 faces\n",
            "[195/243] Processing: 0194.jpg\n",
            "\tdetect 1 faces\n",
            "[196/243] Processing: 0195.jpg\n",
            "\tdetect 1 faces\n",
            "[197/243] Processing: 0196.jpg\n",
            "\tdetect 1 faces\n",
            "[198/243] Processing: 0197.jpg\n",
            "\tdetect 1 faces\n",
            "[199/243] Processing: 0198.jpg\n",
            "\tdetect 1 faces\n",
            "[200/243] Processing: 0199.jpg\n",
            "\tdetect 1 faces\n",
            "[201/243] Processing: 0200.jpg\n",
            "\tdetect 1 faces\n",
            "[202/243] Processing: 0201.jpg\n",
            "\tdetect 1 faces\n",
            "[203/243] Processing: 0202.jpg\n",
            "\tdetect 1 faces\n",
            "[204/243] Processing: 0203.jpg\n",
            "\tdetect 1 faces\n",
            "[205/243] Processing: 0204.jpg\n",
            "\tdetect 1 faces\n",
            "[206/243] Processing: 0205.jpg\n",
            "\tdetect 1 faces\n",
            "[207/243] Processing: 0206.jpg\n",
            "\tdetect 1 faces\n",
            "[208/243] Processing: 0207.jpg\n",
            "\tdetect 1 faces\n",
            "[209/243] Processing: 0208.jpg\n",
            "\tdetect 1 faces\n",
            "[210/243] Processing: 0209.jpg\n",
            "\tdetect 1 faces\n",
            "[211/243] Processing: 0210.jpg\n",
            "\tdetect 1 faces\n",
            "[212/243] Processing: 0211.jpg\n",
            "\tdetect 1 faces\n",
            "[213/243] Processing: 0212.jpg\n",
            "\tdetect 1 faces\n",
            "[214/243] Processing: 0213.jpg\n",
            "\tdetect 1 faces\n",
            "[215/243] Processing: 0214.jpg\n",
            "\tdetect 1 faces\n",
            "[216/243] Processing: 0215.jpg\n",
            "\tdetect 1 faces\n",
            "[217/243] Processing: 0216.jpg\n",
            "\tdetect 1 faces\n",
            "[218/243] Processing: 0217.jpg\n",
            "\tdetect 1 faces\n",
            "[219/243] Processing: 0218.jpg\n",
            "\tdetect 1 faces\n",
            "[220/243] Processing: 0219.jpg\n",
            "\tdetect 1 faces\n",
            "[221/243] Processing: 0220.jpg\n",
            "\tdetect 1 faces\n",
            "[222/243] Processing: 0221.jpg\n",
            "\tdetect 1 faces\n",
            "[223/243] Processing: 0222.jpg\n",
            "\tdetect 1 faces\n",
            "[224/243] Processing: 0223.jpg\n",
            "\tdetect 1 faces\n",
            "[225/243] Processing: 0224.jpg\n",
            "\tdetect 1 faces\n",
            "[226/243] Processing: 0225.jpg\n",
            "\tdetect 1 faces\n",
            "[227/243] Processing: 0226.jpg\n",
            "\tdetect 1 faces\n",
            "[228/243] Processing: 0227.jpg\n",
            "\tdetect 1 faces\n",
            "[229/243] Processing: 0228.jpg\n",
            "\tdetect 1 faces\n",
            "[230/243] Processing: 0229.jpg\n",
            "\tdetect 1 faces\n",
            "[231/243] Processing: 0230.jpg\n",
            "\tdetect 1 faces\n",
            "[232/243] Processing: 0231.jpg\n",
            "\tdetect 1 faces\n",
            "[233/243] Processing: 0232.jpg\n",
            "\tdetect 1 faces\n",
            "[234/243] Processing: 0233.jpg\n",
            "\tdetect 1 faces\n",
            "[235/243] Processing: 0234.jpg\n",
            "\tdetect 1 faces\n",
            "[236/243] Processing: 0235.jpg\n",
            "\tdetect 1 faces\n",
            "[237/243] Processing: 0236.jpg\n",
            "\tdetect 1 faces\n",
            "[238/243] Processing: 0237.jpg\n",
            "\tdetect 1 faces\n",
            "[239/243] Processing: 0238.jpg\n",
            "\tdetect 1 faces\n",
            "[240/243] Processing: 0239.jpg\n",
            "\tdetect 1 faces\n",
            "[241/243] Processing: 0240.jpg\n",
            "\tdetect 1 faces\n",
            "[242/243] Processing: 0241.jpg\n",
            "\tdetect 1 faces\n",
            "[243/243] Processing: 0242.jpg\n",
            "\tdetect 1 faces\n",
            "\n",
            "All results are saved in results/images_0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成修复后的新视频\n",
        "import os\n",
        "restoredFramesPath = '/content/CodeFormer/results/images_0.7' + '/final_results/'\n",
        "processedVideoOutputPath = '/content/output'\n",
        "\n",
        "dir_list = os.listdir(restoredFramesPath)\n",
        "dir_list.sort()\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "batch = 0\n",
        "batchSize = 600\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(0, len(dir_list), batchSize)):\n",
        "  img_array = []\n",
        "  start, end = i, i+batchSize\n",
        "  print(\"processing \", start, end)\n",
        "  for filename in  tqdm(dir_list[start:end]):\n",
        "      filename = restoredFramesPath+filename;\n",
        "      img = cv2.imread(filename)\n",
        "      if img is None:\n",
        "        continue\n",
        "      height, width, layers = img.shape\n",
        "      size = (width,height)\n",
        "      img_array.append(img)\n",
        "\n",
        "\n",
        "  out = cv2.VideoWriter(processedVideoOutputPath+'/batch_'+str(batch).zfill(4)+'.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        "  batch = batch + 1\n",
        "\n",
        "  for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "  out.release()\n",
        "\n",
        "# 音视频合并 Generate audio video\n",
        "audio = ffmpeg.input(f'/content/input/A_10s.wav')\n",
        "video = ffmpeg.input(f'/content/output/batch_0000.avi')\n",
        "print(\"合并视音频\")\n",
        "out = ffmpeg.output(video, audio, f'/content/output/final.mp4')\n",
        "out.run()\n",
        "print(\"恭喜您，音视频合并完成，存放在output/final.mp4\")"
      ],
      "metadata": {
        "id": "tfXGjVvlxRVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "021caafc-6348-4ee3-8cf7-1ea97d9aedc6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing  0 600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/243 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/243 [00:00<00:29,  8.16it/s]\u001b[A\n",
            "  1%|          | 2/243 [00:00<00:30,  7.99it/s]\u001b[A\n",
            "  1%|          | 3/243 [00:00<00:29,  8.00it/s]\u001b[A\n",
            "  2%|▏         | 4/243 [00:00<00:29,  8.11it/s]\u001b[A\n",
            "  2%|▏         | 5/243 [00:00<00:29,  8.16it/s]\u001b[A\n",
            "  2%|▏         | 6/243 [00:00<00:28,  8.28it/s]\u001b[A\n",
            "  3%|▎         | 7/243 [00:00<00:28,  8.22it/s]\u001b[A\n",
            "  3%|▎         | 8/243 [00:00<00:27,  8.57it/s]\u001b[A\n",
            "  4%|▍         | 10/243 [00:01<00:23,  9.74it/s]\u001b[A\n",
            "  5%|▍         | 11/243 [00:01<00:24,  9.63it/s]\u001b[A\n",
            "  5%|▍         | 12/243 [00:01<00:23,  9.63it/s]\u001b[A\n",
            "  6%|▌         | 14/243 [00:01<00:22, 10.20it/s]\u001b[A\n",
            "  7%|▋         | 16/243 [00:01<00:21, 10.70it/s]\u001b[A\n",
            "  7%|▋         | 18/243 [00:01<00:20, 11.01it/s]\u001b[A\n",
            "  8%|▊         | 20/243 [00:02<00:20, 11.11it/s]\u001b[A\n",
            "  9%|▉         | 22/243 [00:02<00:19, 11.23it/s]\u001b[A\n",
            " 10%|▉         | 24/243 [00:02<00:19, 11.11it/s]\u001b[A\n",
            " 11%|█         | 26/243 [00:02<00:19, 11.27it/s]\u001b[A\n",
            " 12%|█▏        | 28/243 [00:02<00:18, 11.37it/s]\u001b[A\n",
            " 12%|█▏        | 30/243 [00:02<00:18, 11.45it/s]\u001b[A\n",
            " 13%|█▎        | 32/243 [00:03<00:18, 11.38it/s]\u001b[A\n",
            " 14%|█▍        | 34/243 [00:03<00:18, 11.42it/s]\u001b[A\n",
            " 15%|█▍        | 36/243 [00:03<00:18, 11.29it/s]\u001b[A\n",
            " 16%|█▌        | 38/243 [00:03<00:18, 11.36it/s]\u001b[A\n",
            " 16%|█▋        | 40/243 [00:03<00:17, 11.39it/s]\u001b[A\n",
            " 17%|█▋        | 42/243 [00:03<00:17, 11.37it/s]\u001b[A\n",
            " 18%|█▊        | 44/243 [00:04<00:18, 10.91it/s]\u001b[A\n",
            " 19%|█▉        | 46/243 [00:04<00:18, 10.77it/s]\u001b[A\n",
            " 20%|█▉        | 48/243 [00:04<00:17, 10.94it/s]\u001b[A\n",
            " 21%|██        | 50/243 [00:04<00:17, 11.13it/s]\u001b[A\n",
            " 21%|██▏       | 52/243 [00:04<00:17, 11.22it/s]\u001b[A\n",
            " 22%|██▏       | 54/243 [00:05<00:16, 11.15it/s]\u001b[A\n",
            " 23%|██▎       | 56/243 [00:05<00:16, 11.23it/s]\u001b[A\n",
            " 24%|██▍       | 58/243 [00:05<00:16, 11.13it/s]\u001b[A\n",
            " 25%|██▍       | 60/243 [00:05<00:16, 11.25it/s]\u001b[A\n",
            " 26%|██▌       | 62/243 [00:05<00:16, 11.18it/s]\u001b[A\n",
            " 26%|██▋       | 64/243 [00:05<00:15, 11.32it/s]\u001b[A\n",
            " 27%|██▋       | 66/243 [00:06<00:15, 11.22it/s]\u001b[A\n",
            " 28%|██▊       | 68/243 [00:06<00:15, 11.23it/s]\u001b[A\n",
            " 29%|██▉       | 70/243 [00:06<00:15, 11.24it/s]\u001b[A\n",
            " 30%|██▉       | 72/243 [00:06<00:15, 11.33it/s]\u001b[A\n",
            " 30%|███       | 74/243 [00:06<00:15, 11.03it/s]\u001b[A\n",
            " 31%|███▏      | 76/243 [00:07<00:14, 11.17it/s]\u001b[A\n",
            " 32%|███▏      | 78/243 [00:07<00:14, 11.08it/s]\u001b[A\n",
            " 33%|███▎      | 80/243 [00:07<00:14, 11.06it/s]\u001b[A\n",
            " 34%|███▎      | 82/243 [00:07<00:14, 11.23it/s]\u001b[A\n",
            " 35%|███▍      | 84/243 [00:07<00:14, 11.33it/s]\u001b[A\n",
            " 35%|███▌      | 86/243 [00:07<00:13, 11.43it/s]\u001b[A\n",
            " 36%|███▌      | 88/243 [00:08<00:13, 11.37it/s]\u001b[A\n",
            " 37%|███▋      | 90/243 [00:08<00:13, 11.32it/s]\u001b[A\n",
            " 38%|███▊      | 92/243 [00:08<00:13, 11.22it/s]\u001b[A\n",
            " 39%|███▊      | 94/243 [00:08<00:13, 11.27it/s]\u001b[A\n",
            " 40%|███▉      | 96/243 [00:08<00:12, 11.34it/s]\u001b[A\n",
            " 40%|████      | 98/243 [00:08<00:12, 11.40it/s]\u001b[A\n",
            " 41%|████      | 100/243 [00:09<00:12, 11.28it/s]\u001b[A\n",
            " 42%|████▏     | 102/243 [00:09<00:12, 11.11it/s]\u001b[A\n",
            " 43%|████▎     | 104/243 [00:09<00:12, 11.23it/s]\u001b[A\n",
            " 44%|████▎     | 106/243 [00:09<00:12, 11.13it/s]\u001b[A\n",
            " 44%|████▍     | 108/243 [00:09<00:12, 11.03it/s]\u001b[A\n",
            " 45%|████▌     | 110/243 [00:10<00:11, 11.12it/s]\u001b[A\n",
            " 46%|████▌     | 112/243 [00:10<00:12, 10.86it/s]\u001b[A\n",
            " 47%|████▋     | 114/243 [00:10<00:12, 10.65it/s]\u001b[A\n",
            " 48%|████▊     | 116/243 [00:10<00:11, 10.86it/s]\u001b[A\n",
            " 49%|████▊     | 118/243 [00:10<00:11, 11.03it/s]\u001b[A\n",
            " 49%|████▉     | 120/243 [00:11<00:11, 10.62it/s]\u001b[A\n",
            " 50%|█████     | 122/243 [00:11<00:12,  9.90it/s]\u001b[A\n",
            " 51%|█████     | 124/243 [00:11<00:12,  9.38it/s]\u001b[A\n",
            " 51%|█████▏    | 125/243 [00:11<00:12,  9.08it/s]\u001b[A\n",
            " 52%|█████▏    | 126/243 [00:11<00:13,  8.81it/s]\u001b[A\n",
            " 52%|█████▏    | 127/243 [00:11<00:13,  8.63it/s]\u001b[A\n",
            " 53%|█████▎    | 128/243 [00:11<00:13,  8.49it/s]\u001b[A\n",
            " 53%|█████▎    | 129/243 [00:12<00:13,  8.40it/s]\u001b[A\n",
            " 53%|█████▎    | 130/243 [00:12<00:13,  8.25it/s]\u001b[A\n",
            " 54%|█████▍    | 131/243 [00:12<00:14,  7.76it/s]\u001b[A\n",
            " 54%|█████▍    | 132/243 [00:12<00:14,  7.74it/s]\u001b[A\n",
            " 55%|█████▍    | 133/243 [00:12<00:14,  7.64it/s]\u001b[A\n",
            " 55%|█████▌    | 134/243 [00:12<00:14,  7.67it/s]\u001b[A\n",
            " 56%|█████▌    | 135/243 [00:12<00:14,  7.69it/s]\u001b[A\n",
            " 56%|█████▌    | 136/243 [00:13<00:13,  7.66it/s]\u001b[A\n",
            " 56%|█████▋    | 137/243 [00:13<00:14,  7.51it/s]\u001b[A\n",
            " 57%|█████▋    | 138/243 [00:13<00:14,  7.50it/s]\u001b[A\n",
            " 57%|█████▋    | 139/243 [00:13<00:12,  8.01it/s]\u001b[A\n",
            " 58%|█████▊    | 141/243 [00:13<00:11,  9.04it/s]\u001b[A\n",
            " 59%|█████▉    | 143/243 [00:13<00:10,  9.69it/s]\u001b[A\n",
            " 60%|█████▉    | 145/243 [00:13<00:09, 10.08it/s]\u001b[A\n",
            " 60%|██████    | 147/243 [00:14<00:09, 10.35it/s]\u001b[A\n",
            " 61%|██████▏   | 149/243 [00:14<00:09,  9.80it/s]\u001b[A\n",
            " 62%|██████▏   | 150/243 [00:14<00:09,  9.78it/s]\u001b[A\n",
            " 62%|██████▏   | 151/243 [00:14<00:09,  9.81it/s]\u001b[A\n",
            " 63%|██████▎   | 152/243 [00:14<00:09,  9.73it/s]\u001b[A\n",
            " 63%|██████▎   | 153/243 [00:14<00:09,  9.71it/s]\u001b[A\n",
            " 63%|██████▎   | 154/243 [00:14<00:09,  9.69it/s]\u001b[A\n",
            " 64%|██████▍   | 156/243 [00:15<00:08,  9.95it/s]\u001b[A\n",
            " 65%|██████▍   | 157/243 [00:15<00:08,  9.92it/s]\u001b[A\n",
            " 65%|██████▌   | 158/243 [00:15<00:08,  9.79it/s]\u001b[A\n",
            " 65%|██████▌   | 159/243 [00:15<00:09,  9.26it/s]\u001b[A\n",
            " 66%|██████▋   | 161/243 [00:15<00:08,  9.83it/s]\u001b[A\n",
            " 67%|██████▋   | 163/243 [00:15<00:07, 10.10it/s]\u001b[A\n",
            " 67%|██████▋   | 164/243 [00:15<00:07, 10.07it/s]\u001b[A\n",
            " 68%|██████▊   | 166/243 [00:16<00:07, 10.29it/s]\u001b[A\n",
            " 69%|██████▉   | 168/243 [00:16<00:07, 10.36it/s]\u001b[A\n",
            " 70%|██████▉   | 170/243 [00:16<00:07, 10.10it/s]\u001b[A\n",
            " 71%|███████   | 172/243 [00:16<00:06, 10.21it/s]\u001b[A\n",
            " 72%|███████▏  | 174/243 [00:16<00:06, 10.27it/s]\u001b[A\n",
            " 72%|███████▏  | 176/243 [00:17<00:06, 10.35it/s]\u001b[A\n",
            " 73%|███████▎  | 178/243 [00:17<00:06, 10.32it/s]\u001b[A\n",
            " 74%|███████▍  | 180/243 [00:17<00:06, 10.19it/s]\u001b[A\n",
            " 75%|███████▍  | 182/243 [00:17<00:05, 10.40it/s]\u001b[A\n",
            " 76%|███████▌  | 184/243 [00:17<00:05, 10.52it/s]\u001b[A\n",
            " 77%|███████▋  | 186/243 [00:18<00:05, 10.62it/s]\u001b[A\n",
            " 77%|███████▋  | 188/243 [00:18<00:05, 10.52it/s]\u001b[A\n",
            " 78%|███████▊  | 190/243 [00:18<00:05, 10.33it/s]\u001b[A\n",
            " 79%|███████▉  | 192/243 [00:18<00:04, 10.34it/s]\u001b[A\n",
            " 80%|███████▉  | 194/243 [00:18<00:04, 10.50it/s]\u001b[A\n",
            " 81%|████████  | 196/243 [00:18<00:04, 10.50it/s]\u001b[A\n",
            " 81%|████████▏ | 198/243 [00:19<00:04, 10.50it/s]\u001b[A\n",
            " 82%|████████▏ | 200/243 [00:19<00:04, 10.05it/s]\u001b[A\n",
            " 83%|████████▎ | 202/243 [00:19<00:04, 10.18it/s]\u001b[A\n",
            " 84%|████████▍ | 204/243 [00:19<00:03, 10.26it/s]\u001b[A\n",
            " 85%|████████▍ | 206/243 [00:19<00:03, 10.40it/s]\u001b[A\n",
            " 86%|████████▌ | 208/243 [00:20<00:03, 10.54it/s]\u001b[A\n",
            " 86%|████████▋ | 210/243 [00:20<00:03, 10.32it/s]\u001b[A\n",
            " 87%|████████▋ | 212/243 [00:20<00:03, 10.26it/s]\u001b[A\n",
            " 88%|████████▊ | 214/243 [00:20<00:02, 10.27it/s]\u001b[A\n",
            " 89%|████████▉ | 216/243 [00:20<00:02, 10.34it/s]\u001b[A\n",
            " 90%|████████▉ | 218/243 [00:21<00:02, 10.38it/s]\u001b[A\n",
            " 91%|█████████ | 220/243 [00:21<00:02, 10.49it/s]\u001b[A\n",
            " 91%|█████████▏| 222/243 [00:21<00:02, 10.25it/s]\u001b[A\n",
            " 92%|█████████▏| 224/243 [00:21<00:01, 10.28it/s]\u001b[A\n",
            " 93%|█████████▎| 226/243 [00:21<00:01, 10.28it/s]\u001b[A\n",
            " 94%|█████████▍| 228/243 [00:22<00:01, 10.38it/s]\u001b[A\n",
            " 95%|█████████▍| 230/243 [00:22<00:01, 10.34it/s]\u001b[A\n",
            " 95%|█████████▌| 232/243 [00:22<00:01, 10.26it/s]\u001b[A\n",
            " 96%|█████████▋| 234/243 [00:22<00:00, 10.25it/s]\u001b[A\n",
            " 97%|█████████▋| 236/243 [00:22<00:00, 10.41it/s]\u001b[A\n",
            " 98%|█████████▊| 238/243 [00:23<00:00, 10.57it/s]\u001b[A\n",
            " 99%|█████████▉| 240/243 [00:23<00:00, 10.53it/s]\u001b[A\n",
            "100%|█████████▉| 242/243 [00:23<00:00,  9.47it/s]\u001b[A\n",
            "100%|██████████| 243/243 [00:23<00:00, 10.28it/s]\n",
            "100%|██████████| 1/1 [00:29<00:00, 29.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "合并视音频\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ffmpeg error (see stderr output for detail)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9ba078a55f05>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"合并视音频\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/content/output/final.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"恭喜您，音视频合并完成，存放在output/final.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ffmpeg/_run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(stream_spec, cmd, capture_stdout, capture_stderr, input, quiet, overwrite_output)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: ffmpeg error (see stderr output for detail)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcfqxXCbtck-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}